{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77b2c04",
   "metadata": {},
   "source": [
    "It's time to finally do actual work with data! If you are here to reproduce code, make sure you run the build_manifest.py first and have generated the `manifest.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c1a52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(ROOT))\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m seed_everything\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m seed_everything(\u001b[43margs\u001b[49m.seed)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Get filepaths from manifest\u001b[39;00m\n\u001b[32m     12\u001b[39m manifest = pd.read_json(\u001b[33m\"\u001b[39m\u001b[33m../data/manifest.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parents[0]\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.utils import seed_everything\n",
    "seed_everything(1337)\n",
    "\n",
    "# Get filepaths from manifest\n",
    "manifest = pd.read_json(\"../data/manifest.json\")\n",
    "\n",
    "df = pd.read_csv(\"../\" + manifest.loc[\"path\", \"filelist\"])\n",
    "manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de44f254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>EF</th>\n",
       "      <th>ESV</th>\n",
       "      <th>EDV</th>\n",
       "      <th>FrameHeight</th>\n",
       "      <th>FrameWidth</th>\n",
       "      <th>FPS</th>\n",
       "      <th>NumberOfFrames</th>\n",
       "      <th>Split</th>\n",
       "      <th>label_hfref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0X100009310A3BD7FC</td>\n",
       "      <td>78.498406</td>\n",
       "      <td>14.881368</td>\n",
       "      <td>69.210534</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>174</td>\n",
       "      <td>VAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0X1002E8FBACD08477</td>\n",
       "      <td>59.101988</td>\n",
       "      <td>40.383876</td>\n",
       "      <td>98.742884</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>215</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0X1005D03EED19C65B</td>\n",
       "      <td>62.363798</td>\n",
       "      <td>14.267784</td>\n",
       "      <td>37.909734</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>104</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0X10075961BC11C88E</td>\n",
       "      <td>54.545097</td>\n",
       "      <td>33.143084</td>\n",
       "      <td>72.914210</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>122</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0X10094BA0A028EAC3</td>\n",
       "      <td>24.887742</td>\n",
       "      <td>127.581945</td>\n",
       "      <td>169.855024</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>52</td>\n",
       "      <td>207</td>\n",
       "      <td>VAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FileName         EF         ESV         EDV  FrameHeight  \\\n",
       "0  0X100009310A3BD7FC  78.498406   14.881368   69.210534          112   \n",
       "1  0X1002E8FBACD08477  59.101988   40.383876   98.742884          112   \n",
       "2  0X1005D03EED19C65B  62.363798   14.267784   37.909734          112   \n",
       "3  0X10075961BC11C88E  54.545097   33.143084   72.914210          112   \n",
       "4  0X10094BA0A028EAC3  24.887742  127.581945  169.855024          112   \n",
       "\n",
       "   FrameWidth  FPS  NumberOfFrames  Split  label_hfref  \n",
       "0         112   50             174    VAL            0  \n",
       "1         112   50             215  TRAIN            0  \n",
       "2         112   50             104  TRAIN            0  \n",
       "3         112   55             122  TRAIN            0  \n",
       "4         112   52             207    VAL            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before I forget, I will add a column label_hfref which is 1 when EF <= 40 else 0\n",
    "# We follow the clinical definition of hfref.\n",
    "df[\"label_hfref\"] = (df[\"EF\"] <= 40).astype(\"int8\")\n",
    "df.columns\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca70b2",
   "metadata": {},
   "source": [
    "## Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47404ff",
   "metadata": {},
   "source": [
    "### 0. Check missing values\n",
    "and do imputations/removals if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7ea9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileName          0\n",
       "EF                0\n",
       "ESV               0\n",
       "EDV               0\n",
       "FrameHeight       0\n",
       "FrameWidth        0\n",
       "FPS               0\n",
       "NumberOfFrames    0\n",
       "Split             0\n",
       "label_hfref       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7729a",
   "metadata": {},
   "source": [
    "### 1. Verify existence of videos according to given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b40784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10030\n",
      "Missing: 0\n",
      "Missing indices: []\n",
      "Missing files: []\n",
      "\n",
      "All clear!\n"
     ]
    }
   ],
   "source": [
    "video_list = df[\"FileName\"]\n",
    "\n",
    "data_dir = Path(\"../\" + manifest.loc[\"root\", \"videos\"])\n",
    "\n",
    "missing_count = 0\n",
    "missing_indices = []\n",
    "missing_files = []\n",
    "\n",
    "# Loop through every video in list and make sure they actually exist.\n",
    "for index, video in video_list.items():\n",
    "    \n",
    "    video = video + \".avi\"  #Include file suffix\n",
    "    \n",
    "    # skip NaN / empty strings safely\n",
    "    if not isinstance(video, str) or not video.strip():\n",
    "        missing_count += 1\n",
    "        missing_indices.append(index)\n",
    "        missing_files.append(video)\n",
    "        continue\n",
    "\n",
    "    path = data_dir / video  # each video path\n",
    "\n",
    "    if not path.is_file():\n",
    "        missing_count += 1\n",
    "        missing_indices.append(index)\n",
    "        missing_files.append(str(path))\n",
    "\n",
    "print(len(video_list))\n",
    "print(\"Missing:\", missing_count)\n",
    "print(\"Missing indices:\", missing_indices)\n",
    "print(\"Missing files:\", missing_files)\n",
    "\n",
    "if missing_count == 0:\n",
    "    print(\"\\nAll clear!\")\n",
    "else:\n",
    "    # drop missing indices\n",
    "    df_e = df.drop(index=missing_indices)\n",
    "    print(\"Missing files detected. Please verify before continuing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45995d78",
   "metadata": {},
   "source": [
    "### 2. Verify video metadata (size, frames)\n",
    "\n",
    "May take up to 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf10fe",
   "metadata": {},
   "source": [
    "The below function serves the purpose of verifying:\n",
    "- Video existence\n",
    "- Correct frame count and FPS\n",
    "- Whether all videos have 112 x 112 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d46e92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "def _sha256_file(path: Path, chunk_size: int = 1024 * 1024) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def verify_avis_against_df(\n",
    "    df: pd.DataFrame,\n",
    "    base_dir,\n",
    "    file_col=\"FileName\",\n",
    "    expected_fps_col=\"FPS\",\n",
    "    expected_frames_col=\"NumberOfFrames\",\n",
    "    fps_tol=0.25,          # tolerance for fps floats (tweak if needed)\n",
    "    default_ext=\".avi\",\n",
    "    expected_width=112,\n",
    "    expected_height=112,\n",
    "    id_col=None,           # Name of ID Column\n",
    "    compute_sha256=False, \n",
    "):\n",
    "    base_dir = Path(base_dir)\n",
    "    count = 0\n",
    "    rows = []\n",
    "    \n",
    "    for _, r in df.iterrows():\n",
    "        name = str(r[file_col])\n",
    "        # add .avi if missing\n",
    "        if not name.lower().endswith(default_ext):\n",
    "            name = name + default_ext\n",
    "\n",
    "        # Video File Path\n",
    "        p = base_dir / name\n",
    "\n",
    "        exists = p.is_file()\n",
    "        size_bytes = p.stat().st_size if exists else 0\n",
    "        size_ok = exists and size_bytes > 0\n",
    "\n",
    "        opened = False\n",
    "        actual_fps = np.nan\n",
    "        actual_frames = np.nan\n",
    "        actual_width = np.nan\n",
    "        actual_height = np.nan\n",
    "        sha256 = None\n",
    "\n",
    "        if size_ok:\n",
    "            if compute_sha256:\n",
    "                # exact byte-for-byte identity\n",
    "                sha256 = _sha256_file(p)\n",
    "                \n",
    "            cap = cv2.VideoCapture(str(p))\n",
    "            opened = cap.isOpened()\n",
    "            if opened:\n",
    "                actual_fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "                actual_frames = int(round(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "                actual_width = int(round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "                actual_height = int(round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "                count += 1\n",
    "            cap.release()\n",
    "            \n",
    "\n",
    "        exp_fps = float(r[expected_fps_col])\n",
    "        exp_frames = int(r[expected_frames_col])\n",
    "\n",
    "        fps_ok = opened and np.isfinite(actual_fps) and (abs(actual_fps - exp_fps) <= fps_tol)\n",
    "        frames_ok = opened and np.isfinite(actual_frames) and (int(actual_frames) == exp_frames)\n",
    "\n",
    "        resolution_ok = (\n",
    "            opened\n",
    "            and np.isfinite(actual_width) and np.isfinite(actual_height)\n",
    "            and int(actual_width) == int(expected_width)\n",
    "            and int(actual_height) == int(expected_height)\n",
    "        )\n",
    "        \n",
    "        ok = size_ok and opened and fps_ok and frames_ok and resolution_ok\n",
    "\n",
    "        row_out = {\n",
    "            file_col: r[file_col],\n",
    "            \"path\": str(p),\n",
    "            \"exists\": exists,\n",
    "            \"size_bytes\": size_bytes,\n",
    "            \"opened\": opened,\n",
    "            \"expected_fps\": exp_fps,\n",
    "            \"actual_fps\": actual_fps,\n",
    "            \"expected_frames\": exp_frames,\n",
    "            \"actual_frames\": actual_frames,\n",
    "            \"expected_width\": int(expected_width),\n",
    "            \"actual_width\": actual_width,\n",
    "            \"expected_height\": int(expected_height),\n",
    "            \"actual_height\": actual_height,\n",
    "            \"size_ok\": size_ok,\n",
    "            \"fps_ok\": fps_ok,\n",
    "            \"frames_ok\": frames_ok,\n",
    "            \"resolution_ok\": resolution_ok,\n",
    "            \"sha256\": sha256,\n",
    "            \"ok\": ok,\n",
    "        }\n",
    "        \n",
    "        if id_col is not None:\n",
    "            row_out[id_col] = r[id_col]\n",
    "\n",
    "        rows.append(row_out)\n",
    "\n",
    "    report = pd.DataFrame(rows)\n",
    "    return report, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731d1ed",
   "metadata": {},
   "source": [
    "Next, we verify that all videos are unique, i.e. no duplicates under different names. We do this by comparing the SHA256 codes of the videos (The actual code that extracts SHA256 is in the previous block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8c09d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_identical_videos_within_id(report: pd.DataFrame, id_col: str, hash_col: str = \"sha256\") -> pd.DataFrame:\n",
    "    # Only consider rows that actually produced a hash\n",
    "    x = report[report[hash_col].notna()].copy()\n",
    "\n",
    "    # keep=False marks all members of a duplicate group\n",
    "    x[\"identical_within_id\"] = x.duplicated(subset=[id_col, hash_col], keep=False)\n",
    "\n",
    "    # Return only the duplicate groups (sorted for readability)\n",
    "    dupes = x[x[\"identical_within_id\"]].sort_values([id_col, hash_col, \"path\"])\n",
    "    return dupes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "290c6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, count = verify_avis_against_df(\n",
    "    df,\n",
    "    base_dir=data_dir,\n",
    "    id_col=\"FileName\",\n",
    "    compute_sha256=True\n",
    ")\n",
    "\n",
    "dupes_within_id = find_identical_videos_within_id(report, id_col=\"FileName\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a5c35",
   "metadata": {},
   "source": [
    "If all videos are within expectations, then the below should return empty dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a95a105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [FileName, path, exists, size_bytes, opened, expected_fps, actual_fps, expected_frames, actual_frames, expected_width, actual_width, expected_height, actual_height, size_ok, fps_ok, frames_ok, resolution_ok, sha256, ok, identical_within_id]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [FileName, path, exists, size_bytes, opened, expected_fps, actual_fps, expected_frames, actual_frames, expected_width, actual_width, expected_height, actual_height, size_ok, fps_ok, frames_ok, resolution_ok, sha256, ok]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(dupes_within_id)\n",
    "print(report[report[\"ok\"] != True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb10f33",
   "metadata": {},
   "source": [
    "We also make sure ejection fraction is within expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60b4dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [FileName, EF, ESV, EDV, FrameHeight, FrameWidth, FPS, NumberOfFrames, Split, label_hfref]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "weird_EF = df[(df[\"EF\"] > 100) | df[\"EF\"]< 0 ]\n",
    "print(weird_EF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a6e59",
   "metadata": {},
   "source": [
    "Final check, we take a random sample of 200 videos and make sure we can actually open them. Specifically we will try opening the beginning, middle, and last frames of the video.\n",
    "\n",
    "I expect good results given how clean the data is, but it never hurts to re-check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d66ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def decoding_sanity_check(\n",
    "    df: pd.DataFrame,\n",
    "    video_root: str,\n",
    "    filename_col: str = \"FileName\",\n",
    "    sample_n: int = 50,\n",
    "    seed: int = 42,\n",
    "    # probe a few points in the video (start/middle/end by default)\n",
    "    probe_fracs=(0.0, 0.5, 0.9),\n",
    "    # when probing, allow a few sequential reads in case the exact seek lands oddly\n",
    "    reads_per_probe: int = 2,\n",
    "    require_nonblank: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Randomly sample videos and confirm we can decode frames at multiple positions.\n",
    "    This is a stronger corruption/codec check than just reading the first frame.\n",
    "\n",
    "    Returns:\n",
    "      report_df: per-video results including how many probes succeeded\n",
    "      missing_files: list of missing paths (not sampled)\n",
    "    \"\"\"\n",
    "    if filename_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{filename_col}' not found in df columns: {list(df.columns)}\")\n",
    "\n",
    "    # Build candidate list of paths\n",
    "    candidates = []\n",
    "    for fn in df[filename_col].dropna().astype(str).tolist():\n",
    "        path = os.path.join(video_root, fn)\n",
    "        if not os.path.splitext(path)[1]:\n",
    "            path = path + \".avi\"\n",
    "        candidates.append(path)\n",
    "\n",
    "    missing = [p for p in candidates if not os.path.exists(p)]\n",
    "    existing = [p for p in candidates if os.path.exists(p)]\n",
    "    if len(existing) == 0:\n",
    "        raise RuntimeError(\"No existing videos found to sample from. Check video_root / filenames.\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    sample_n = min(sample_n, len(existing))\n",
    "    sampled = random.sample(existing, sample_n)\n",
    "\n",
    "    results = []\n",
    "    for path in sampled:\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        row = {\n",
    "            \"path\": path,\n",
    "            \"opened\": False,\n",
    "            \"frame_count\": None,\n",
    "            \"probes_ok\": 0,\n",
    "            \"probes_total\": len(probe_fracs),\n",
    "            \"decoded\": False,\n",
    "            \"reason\": \"\",\n",
    "        }\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            row[\"reason\"] = \"cap_not_opened\"\n",
    "            results.append(row)\n",
    "            continue\n",
    "\n",
    "        row[\"opened\"] = True\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "        row[\"frame_count\"] = frame_count\n",
    "\n",
    "        if frame_count <= 0:\n",
    "            # Some containers/backends may not report frame count reliably; still try without seeking.\n",
    "            frame_count = 0\n",
    "\n",
    "        probe_fail_reasons = []\n",
    "\n",
    "        for frac in probe_fracs:\n",
    "            # Pick a target frame index (if we know frame_count)\n",
    "            if frame_count > 0:\n",
    "                target = int(frac * (frame_count - 1))\n",
    "                target = max(0, min(target, frame_count - 1))\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, target)\n",
    "            else:\n",
    "                # Fallback: just continue sequentially\n",
    "                target = None\n",
    "\n",
    "            ok_this_probe = False\n",
    "            last_reason = \"read_failed\"\n",
    "\n",
    "            for _ in range(reads_per_probe):\n",
    "                ok, frame = cap.read()\n",
    "                if not ok or frame is None:\n",
    "                    last_reason = \"read_failed\"\n",
    "                    continue\n",
    "                if frame.size == 0:\n",
    "                    last_reason = \"empty_frame\"\n",
    "                    continue\n",
    "                if require_nonblank and np.std(frame) == 0:\n",
    "                    last_reason = \"blank_frame_std0\"\n",
    "                    continue\n",
    "\n",
    "                ok_this_probe = True\n",
    "                break\n",
    "\n",
    "            if ok_this_probe:\n",
    "                row[\"probes_ok\"] += 1\n",
    "            else:\n",
    "                where = f\"frac={frac}\"\n",
    "                if target is not None:\n",
    "                    where += f\",target={target}\"\n",
    "                probe_fail_reasons.append(f\"{where}:{last_reason}\")\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        row[\"decoded\"] = (row[\"probes_ok\"] == row[\"probes_total\"])\n",
    "        row[\"reason\"] = \"\" if row[\"decoded\"] else \";\".join(probe_fail_reasons)[:500]\n",
    "        results.append(row)\n",
    "\n",
    "    report = pd.DataFrame(results)\n",
    "    failed = report[~report[\"decoded\"]]\n",
    "\n",
    "    print(f\"Decoding sanity check: {sample_n} sampled\")\n",
    "    print(f\"Missing files (not sampled): {len(missing)}\")\n",
    "    print(f\"Decode failures in sample: {len(failed)}\")\n",
    "    if len(failed) > 0:\n",
    "        display(failed[[\"path\", \"frame_count\", \"probes_ok\", \"probes_total\", \"reason\"]].head(20))\n",
    "\n",
    "    return report, missing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2a6187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding sanity check: 200 sampled\n",
      "Missing files (not sampled): 0\n",
      "Decode failures in sample: 0\n"
     ]
    }
   ],
   "source": [
    "report_df, missing_files = decoding_sanity_check(\n",
    "    df,\n",
    "    video_root=data_dir,\n",
    "    sample_n=200,\n",
    "    probe_fracs=(0.0, 0.5, 0.9),\n",
    "    reads_per_probe=2\n",
    ")\n",
    "report_df.to_csv(\"decoding_probe_report.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
